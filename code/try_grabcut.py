import numpy as np
import argparse
import time
import cv2
import os

if __name__ == '__main__':
    from imageio.v2 import imread
    import matplotlib.pyplot as plt
    import numpy as np
    import json
    json_data = None
    label_dir = '../data/serengeti_bboxes/labels/'
    image_dir = '../data/serengeti_bboxes/images/'
    data_dir = '../data/'
    with open('../data/bbox_species.json') as json_file:
        json_data = json.load(json_file)
        json_file.close()

    image_ids = list(set([annot['image_id'] for annot in json_data]))

    image_id = image_ids[15]
    filename = image_id.split('/')[-1]
    bboxes = [annot for annot in json_data if annot['image_id'] == image_id]

    x, y, w, h = bboxes[0]['bbox']  # origin at upper-left

    print(x,y,w,h)

    # We want to change this to use the bbox produced by yolo

    image = cv2.imread(image_dir + filename + '.JPG')

    mask = np.zeros(image.shape[:2], dtype="uint8")

    #bbox = np.array([x, y, x+w, y, x+w, y+h, x, y+h])

    bbox = (int(x), int(y), int(x+w), int(y+h))

    fgModel = np.zeros((1, 65), dtype="float")
    bgModel = np.zeros((1, 65), dtype="float")

    iterations = 5

    # apply GrabCut using the the bounding box segmentation method
    (mask, bgModel, fgModel) = cv2.grabCut(image, mask, bbox, bgModel,
                                           fgModel, iterCount=iterations, mode=cv2.GC_INIT_WITH_RECT)



    values = (
        ("Definite Background", cv2.GC_BGD),
        ("Probable Background", cv2.GC_PR_BGD),
        ("Definite Foreground", cv2.GC_FGD),
        ("Probable Foreground", cv2.GC_PR_FGD),
    )

    cv2.imshow('image', image)
    # loop over the possible GrabCut mask values
    outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),
                          0, 1)
    # scale the mask from the range [0, 1] to [0, 255]
    outputMask = (outputMask * 255).astype("uint8")
    # apply a bitwise AND to the image using our mask generated by
    # GrabCut to generate our final output image
    output = cv2.bitwise_and(image, image, mask=outputMask)

    cv2.imshow("output", output)

    cv2.waitKey(0)

    exit()

    for (name, value) in values:
        # construct a mask that for the current value
        print("[INFO] showing mask for '{}'".format(name))
        valueMask = (mask == value).astype("uint8") * 255
        # display the mask so we can visualize it
        cv2.imshow(name, valueMask)
        cv2.waitKey(0)

    exit()
    # from scipy.ndimage import imread
    from imageio.v2 import imread
    import matplotlib.pyplot as plt

    # apply segmentation bag image (from VOT2016 data set)
    #image = imread('images/bag_00000001.jpg')
    #bbox = np.array([334.02, 128.36, 438.19, 188.78,
    #                 396.39, 260.83, 292.23, 200.41])

    #mask, [x0, y0, x1, y1] = perform_alpha_matting(image, bbox, return_crop_region=True)

    #mask, [x0, y0, x1, y1] = perform_ocsvm_segmentation(image, bbox, return_crop_region=True)

    #mask, [x0, y0, x1, y1] = perform_SBBM_segmentation(image, bbox, return_crop_region=True)

    # remove pixels from image that are labelled as background
    image_masked = image.copy()
    for d in range(3):
        image_masked[..., d].flat[~mask.ravel()] = 255

    # display original image, segmentation, and segmented image
    images = [image[y0:y1, x0:x1, :], mask[y0:y1, x0:x1], image_masked[y0:y1, x0:x1]]
    titles = ['Original image (cropped)', 'Segmentation', 'Segmented image']

    bbox_pts = np.concatenate((np.reshape(bbox, (-1, 2)), bbox[:2][np.newaxis, :]))
    bbox_pts -= [x0, y0]

    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))
    for image, title, a in zip(images, titles, ax.flat):
        a.imshow(image)
        for i in range(4):
            a.plot(bbox_pts[i:i + 2, 0], bbox_pts[i:i + 2, 1], 'c-', lw=2)
        a.set_title(title)
        a.axis('off')
    plt.show()
